{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('aviation_csv.csv', delimiter=',', encoding='cp1252', low_memory=False)\n",
    "df = df[(df.event_year >= 1982) & (df.event_year <= 2007)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Latitude = pd.to_numeric(df.Latitude, errors = 'coerce')\n",
    "df.Longitude = pd.to_numeric(df.Longitude, errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.replace('.','_')\n",
    "df.columns = df.columns.str.lower()\n",
    "df.rename(columns={'total_uninjured': 'uninjured',\n",
    "                   'total_minor_injuries': 'minor_inj',\n",
    "                   'total_serious_injuries': 'serious_inj',\n",
    "                   'total_fatal_injuries': 'fatal_inj',\n",
    "                   'broad_phase_of_flight' : 'flight_phase',\n",
    "                   'phase_of_flight' : 'flight_phase',\n",
    "                   'purpose_of_flight' : 'flight_purpose',\n",
    "                   'amateur_built' : 'is_amateur_built'}, inplace = True)\n",
    "\n",
    "df.drop(columns={'injury_severity',\n",
    "                 'publication_date',\n",
    "                 'airport_code',\n",
    "                 'airport_name',\n",
    "                 'air_carrier',\n",
    "                 'report_status'}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_fatal'] = df['fatal_inj'].fillna(0).apply(lambda record: record >= 1)\n",
    "df[['fatal_inj', 'serious_inj', 'minor_inj', 'uninjured']].fillna(0)\n",
    "def convert_amateur_built(record):\n",
    "    if record == 'Y' or record == 'Yes':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "df['is_amateur_built'] = df['is_amateur_built'].apply(convert_amateur_built)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['flight_phase'].fillna('Unknown')\n",
    "df['location'] = df['location'].fillna('NO DATA')\n",
    "df['location'] = df['location'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing latidude and longitude\n",
    "new_lat_list = []\n",
    "new_lng_list = []\n",
    "geometry_cache = {}\n",
    "api_counter = 0\n",
    "already_entered = 0\n",
    "error_counter = 0\n",
    "max = 0 # Change value\n",
    "\n",
    "API_KEY = os.environ.get('GOOGLE_API_KEY')\n",
    "\n",
    "# Iterate over latitude, longitude, and location in parallel\n",
    "for original_lat, original_lng, location in zip(df.latitude, df.longitude, df.location):\n",
    "\n",
    "    while api_counter < max:  # Don't go broke\n",
    "\n",
    "        if location not in geometry_cache:  # Check if location is not in the cache\n",
    "\n",
    "            if pd.isnull(original_lat):  # Check if original latitude is missing\n",
    "\n",
    "                params = {\n",
    "                    'key': API_KEY,\n",
    "                    'address': location\n",
    "                }\n",
    "                base_url = 'https://maps.googleapis.com/maps/api/geocode/json?'\n",
    "\n",
    "                # Send geocoding request and get response\n",
    "                response = requests.get(base_url, params=params).json()\n",
    "\n",
    "                if response['status'] == 'OK':  # If geocoding request is successful\n",
    "\n",
    "                    geometry = response['results'][0]['geometry']\n",
    "                    new_lat = geometry['location']['lat']\n",
    "                    new_lng = geometry['location']['lng']\n",
    "                    api_counter += 1  # Increment API call counter\n",
    "\n",
    "                else:  # If geocoding request encounters an error\n",
    "                    new_lat, new_lng = 'Error', 'Error'\n",
    "                    error_counter += 1  # Increment error counter\n",
    "\n",
    "            else:  # If original latitude is present\n",
    "                new_lat = original_lat\n",
    "                new_lng = original_lng\n",
    "                already_entered += 1  # Increment already entered counter\n",
    "\n",
    "            geometry_cache[location] = [new_lat, new_lng]  # Cache the new latitude and longitude\n",
    "\n",
    "        elif location in geometry_cache:  # If location is already in the cache\n",
    "            new_lat = geometry_cache[location][0]  # Retrieve latitude from the cache\n",
    "            new_lng = geometry_cache[location][1]  # Retrieve longitude from the cache\n",
    "\n",
    "        new_lat_list.append(new_lat)  # Append new latitude to the list\n",
    "        new_lng_list.append(new_lng)  # Append new longitude to the list\n",
    "\n",
    "print(f'{api_counter} API calls')  # Print the number of API calls made\n",
    "print(f'{already_entered} already in the database')  # Print the number of locations already present\n",
    "print(f'{error_counter} errors')  # Print the number of errors encountered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(6,'lat', new_lat_list)\n",
    "df.insert(7,'lng', new_lng_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_export = df.copy()\n",
    "df_export.drop(columns={'latitude', 'longitude'}, inplace=True)\n",
    "df_export.to_csv('cleaned_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
